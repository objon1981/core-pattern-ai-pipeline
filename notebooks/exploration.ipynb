{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b18747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc82da21",
   "metadata": {},
   "source": [
    "# exploration.ipynb\n",
    "\n",
    "# ## Core Pattern AI Pipeline Exploration\n",
    "\n",
    "# This notebook demonstrates initial experiments with core modules:\n",
    "# - Wavelet Transform\n",
    "# - Universal Graph Converter\n",
    "# - Core Pattern Learner\n",
    "# - Visualization\n",
    "# - Model saving/loading\n",
    "\n",
    "# --- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847093db",
   "metadata": {},
   "source": [
    "# Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d9f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./src')  # Adjust if needed\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from wavelet_transformer import WaveletTransformer\n",
    "from universal_graph_converter import UniversalGraphConverter\n",
    "from core_pattern_learner import CorePatternLearner\n",
    "from visualization import plot_graph\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eff91a",
   "metadata": {},
   "source": [
    "# --- \n",
    "\n",
    "# Load example data (replace with your own dataset path)\n",
    "# For demonstration, let's create a sample signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7746cb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "signal = np.sin(np.linspace(0, 4*np.pi, 256)) + 0.5 * np.random.randn(256)\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(signal)\n",
    "plt.title('Sample Signal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f7a1f0",
   "metadata": {},
   "source": [
    "# 1. Initialize Wavelet Transformer and transform the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8578227",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet_transformer = WaveletTransformer(wavelet='db4', level=3)\n",
    "coeffs = wavelet_transformer.transform(signal)\n",
    "\n",
    "print(f\"Wavelet Coefficients (level 3):\")\n",
    "for i, coef in enumerate(coeffs):\n",
    "    print(f\"Level {i}: shape={coef.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049ad9b",
   "metadata": {},
   "source": [
    "# Visualize Approximation Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ca4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(coeffs[0])\n",
    "plt.title('Approximation Coefficients (Level 3)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7fb514",
   "metadata": {},
   "source": [
    "# ---\n",
    "\n",
    "# 2. Convert signal to graph representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fe9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_converter = UniversalGraphConverter()\n",
    "G = graph_converter.signal_to_graph(signal)\n",
    "\n",
    "print(f\"Graph info: Nodes={G.number_of_nodes()}, Edges={G.number_of_edges()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6bef60",
   "metadata": {},
   "source": [
    "# Visualize graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f7208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plot_graph(G)\n",
    "plt.title('Graph Representation of Signal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6822048b",
   "metadata": {},
   "source": [
    "# ---\n",
    "\n",
    "# 3. Initialize Core Pattern Learner and perform a dummy forward pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f25d3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 256  # example, adjust accordingly\n",
    "hidden_dim = 128\n",
    "output_dim = 10  # example task classes or output size\n",
    "\n",
    "learner = CorePatternLearner(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fff52e",
   "metadata": {},
   "source": [
    "# Create dummy input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7858823",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, input_dim)\n",
    "\n",
    "output = learner.model(dummy_input)\n",
    "print(f\"Model output shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535ad61",
   "metadata": {},
   "source": [
    "# ---\n",
    "\n",
    "# 4. Save and load the model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c4a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/core_pattern_learner.pth'\n",
    "\n",
    "learner.save_model(model_path)\n",
    "learner.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ae0de9",
   "metadata": {},
   "source": [
    "# 5. Final notes: further exploration can involve training loops, dataset integration, LLM explanation etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
